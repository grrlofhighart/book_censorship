{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping a dataset of Top Banned Books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By [Crystal Shearer](https://grrlofhighart.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will outline the steps I took to compile a dataset of top banned books from [Goodreads](https://www.Goodreads.com). My original intention was to utilize a readily available dataset from a website such as [Kaggle](https://www.kaggle.com). However, after some searching it seemed like all the available datasets were lacking many of the data points I was hoping to utilize. My only solution was to attempt compiling my own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is best ran from the command line or Terminal. Before getting started go ahead and navigate into the `/book_dataset` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd book_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project to run you will need to install the required Python packages. If you have not previously done so, now is the time. I typically prefer to use a virtual environment. If you are using [VS Code](https://code.visualstudio.com/docs/setup/setup-overview) you can create the virtual environment and install the required packages all at once. Open the Command Palette with [(Ctrl + Shift + P)](https://code.visualstudio.com/docs/python/environments#_creating-environments), search for and select the command `Python: Create Environment`. Select your choice from the list of environment types. (`Venv` would be our default if no other options.) Finally, select a current version of Python from the list of Interpreters and check the box for requirements.txt. Click `OK` and your virtual environment should be created and initiated assuming there are no issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aren't down with VS Code, you can [create a virtual environment](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#create-and-use-virtual-environments) and [install the required packages](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#install-packages-using-pip) right from the command line. You can find a guide on virtual environments on [python.org](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!py -m venv .venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!.venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing all the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy for working with arrays\n",
    "import numpy as np\n",
    "\n",
    "# pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# BeautifulSoup for navigating webdata \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# requests fetching data\n",
    "import requests\n",
    "\n",
    "# re for working with regular expressions (strings)\n",
    "import re\n",
    "\n",
    "# sqlite3 for communicating with SQLite\n",
    "import sqlite3\n",
    "from contextlib import closing\n",
    "\n",
    "# time to aid in webscraping\n",
    "import time\n",
    "\n",
    "# selenium for fetching dynamic web content\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setting up the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan on collecting multiple datasets throughout this project. To keep everything uniform I decided to store my data in a sql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup SQLite Database\n",
    "database = 'Book_DB.db'\n",
    "conn = sqlite3.connect(database)\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setting scrape parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found a list on Goodreads Listopia called `Best Banned, Censored, and Challenged Books`. According to the list description, the list is comprised of \"books that have at one point either been banned, censored, or requested for removal from libraries\". The list contains over 700 books which I am sure includes many, if not all, of the books from the ALA Top Banned Books lists. Lists on Goodreads only display 100 books per page, so there are at least 8 pages that need to be scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base url and number of pages to scrape\n",
    "# Add header to avoid '403' errors\n",
    "base_url = 'https://www.goodreads.com/list/show/1360.Best_Banned_Censored_and_Challenged_Books?page='\n",
    "pages = 8\n",
    "header = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scraping the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup empty list to store data\n",
    "TopBannedBooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a for loop to scrape all books from the List pages\n",
    "for page_num in range(1, pages + 1):\n",
    "    BannedList = {}\n",
    "    # Construct the URL for the current page\n",
    "    URL = base_url + str(page_num)\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(URL, headers=header)\n",
    "\n",
    "    BannedBooks  = (response).content\n",
    "    \n",
    "    ## Grabbing all tags in webpage of 'a' type and class 'bookTitle'\n",
    "    soup = BeautifulSoup(BannedBooks,\"lxml\")\n",
    "    block = soup.select('a.bookTitle')\n",
    "\n",
    "    ## Iterating through and creating list for all titles (bookT) and links (bookLink)\n",
    "    bookT = [x.text.strip() for x in block]\n",
    "    bookLink = ['https://www.goodreads.com'+ x.get('href') for x in block]\n",
    "\n",
    "    ## Combining list\n",
    "    col_stack = np.column_stack((bookT, bookLink))\n",
    "    # TopBannedBooks = pd.DataFrame(con, columns = ['title', 'bklink'])\n",
    "    # BannedList = [bookT, bookLink]\n",
    "    TopBannedBooks.append(col_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(np.concatenate(TopBannedBooks), columns = ['title', 'bklink'])\n",
    "BookID = [re.search(r'\\d+', i)[0] for i in df['bklink']]\n",
    "df['bookID'] = BookID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bklink</th>\n",
       "      <th>bookID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>https://www.goodreads.com/book/show/3.Harry_Po...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984</td>\n",
       "      <td>https://www.goodreads.com/book/show/61439040-1984</td>\n",
       "      <td>61439040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>https://www.goodreads.com/book/show/7613.Anima...</td>\n",
       "      <td>7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fahrenheit 451</td>\n",
       "      <td>https://www.goodreads.com/book/show/13079982-f...</td>\n",
       "      <td>13079982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                              To Kill a Mockingbird   \n",
       "1  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
       "2                                               1984   \n",
       "3                                        Animal Farm   \n",
       "4                                     Fahrenheit 451   \n",
       "\n",
       "                                              bklink    bookID  \n",
       "0  https://www.goodreads.com/book/show/2657.To_Ki...      2657  \n",
       "1  https://www.goodreads.com/book/show/3.Harry_Po...         3  \n",
       "2  https://www.goodreads.com/book/show/61439040-1984  61439040  \n",
       "3  https://www.goodreads.com/book/show/7613.Anima...      7613  \n",
       "4  https://www.goodreads.com/book/show/13079982-f...  13079982  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export copy of DataFrame to database\n",
    "# df.to_sql(name='goodreads_list', con=conn, if_exists='append', index=False)\n",
    "df.to_sql(name='goodreads_original', con=conn, if_exists='append', index=False)\n",
    "# If not using sqlite you can also export a copy to csv\n",
    "# df.to_csv('goodreads_list_original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove parentheses and information within from title column\n",
    "df['title'] = df['title'].str.replace(r'\\([^()]*\\)', '', regex=True)\n",
    "\n",
    "# Remove special characters from title column\n",
    "df['title'] = df['title'].str.replace(r'[\\'\\.+\\`\\|\\#\\:\\’\\*+]', '', regex=True)\n",
    "\n",
    "# Change bookID to dtype int\n",
    "df['bookID'] = df['bookID'].astype(int)\n",
    "\n",
    "# Sort dataframe alphabetically by title\n",
    "df = df.sort_values('title')\n",
    "\n",
    "# Remove leading and trailing whitespaces from dataframe\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bklink</th>\n",
       "      <th>bookID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1001 Comics You Must Read Before You Die The U...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10469840-1...</td>\n",
       "      <td>10469840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984</td>\n",
       "      <td>https://www.goodreads.com/book/show/61439040-1984</td>\n",
       "      <td>61439040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>22s Diary</td>\n",
       "      <td>https://www.goodreads.com/book/show/34828777-2...</td>\n",
       "      <td>34828777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>A Bad Boy Can Be Good for a Girl</td>\n",
       "      <td>https://www.goodreads.com/book/show/584937.A_B...</td>\n",
       "      <td>584937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>A Butler Christmas</td>\n",
       "      <td>https://www.goodreads.com/book/show/35295478-a...</td>\n",
       "      <td>35295478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Z</td>\n",
       "      <td>https://www.goodreads.com/book/show/871294.Z</td>\n",
       "      <td>871294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Zero</td>\n",
       "      <td>https://www.goodreads.com/book/show/608787.Zero</td>\n",
       "      <td>608787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Zhuan Falun</td>\n",
       "      <td>https://www.goodreads.com/book/show/19869794-z...</td>\n",
       "      <td>19869794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>ttyl</td>\n",
       "      <td>https://www.goodreads.com/book/show/301023.ttyl</td>\n",
       "      <td>301023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>大江大海一九四九</td>\n",
       "      <td>https://www.goodreads.com/book/show/11385665</td>\n",
       "      <td>11385665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "486  1001 Comics You Must Read Before You Die The U...   \n",
       "2                                                 1984   \n",
       "369                                          22s Diary   \n",
       "718                   A Bad Boy Can Be Good for a Girl   \n",
       "477                                 A Butler Christmas   \n",
       "..                                                 ...   \n",
       "379                                                  Z   \n",
       "389                                               Zero   \n",
       "713                                        Zhuan Falun   \n",
       "717                                               ttyl   \n",
       "570                                           大江大海一九四九   \n",
       "\n",
       "                                                bklink    bookID  \n",
       "486  https://www.goodreads.com/book/show/10469840-1...  10469840  \n",
       "2    https://www.goodreads.com/book/show/61439040-1984  61439040  \n",
       "369  https://www.goodreads.com/book/show/34828777-2...  34828777  \n",
       "718  https://www.goodreads.com/book/show/584937.A_B...    584937  \n",
       "477  https://www.goodreads.com/book/show/35295478-a...  35295478  \n",
       "..                                                 ...       ...  \n",
       "379       https://www.goodreads.com/book/show/871294.Z    871294  \n",
       "389    https://www.goodreads.com/book/show/608787.Zero    608787  \n",
       "713  https://www.goodreads.com/book/show/19869794-z...  19869794  \n",
       "717    https://www.goodreads.com/book/show/301023.ttyl    301023  \n",
       "570       https://www.goodreads.com/book/show/11385665  11385665  \n",
       "\n",
       "[705 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only unique values \n",
    "df = df.drop_duplicates(subset='title')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 24,\n",
       " 30,\n",
       " 33,\n",
       " 34,\n",
       " 249,\n",
       " 264,\n",
       " 295,\n",
       " 330,\n",
       " 343,\n",
       " 662,\n",
       " 890,\n",
       " 929,\n",
       " 960,\n",
       " 968,\n",
       " 1303,\n",
       " 1420,\n",
       " 1519,\n",
       " 1554,\n",
       " 1591,\n",
       " 1617,\n",
       " 1618,\n",
       " 1622,\n",
       " 1625,\n",
       " 1848,\n",
       " 1852,\n",
       " 1869,\n",
       " 1934,\n",
       " 1953,\n",
       " 2122,\n",
       " 2165,\n",
       " 2175,\n",
       " 2187,\n",
       " 2316,\n",
       " 2657,\n",
       " 2696,\n",
       " 2767,\n",
       " 2839,\n",
       " 2865,\n",
       " 2956,\n",
       " 2997,\n",
       " 3103,\n",
       " 3636,\n",
       " 3685,\n",
       " 3835,\n",
       " 3863,\n",
       " 3876,\n",
       " 4406,\n",
       " 4473,\n",
       " 4671,\n",
       " 4708,\n",
       " 4900,\n",
       " 4909,\n",
       " 4953,\n",
       " 4981,\n",
       " 5043,\n",
       " 5107,\n",
       " 5129,\n",
       " 5148,\n",
       " 5209,\n",
       " 5220,\n",
       " 5297,\n",
       " 5308,\n",
       " 5326,\n",
       " 5368,\n",
       " 5527,\n",
       " 5693,\n",
       " 5805,\n",
       " 5854,\n",
       " 6149,\n",
       " 6295,\n",
       " 6310,\n",
       " 6327,\n",
       " 6328,\n",
       " 6333,\n",
       " 6440,\n",
       " 6514,\n",
       " 6689,\n",
       " 7437,\n",
       " 7445,\n",
       " 7588,\n",
       " 7604,\n",
       " 7613,\n",
       " 7624,\n",
       " 7777,\n",
       " 8732,\n",
       " 8737,\n",
       " 8909,\n",
       " 9328,\n",
       " 9516,\n",
       " 9646,\n",
       " 9777,\n",
       " 10210,\n",
       " 10592,\n",
       " 10603,\n",
       " 10614,\n",
       " 10629,\n",
       " 10799,\n",
       " 10917,\n",
       " 10964,\n",
       " 11012,\n",
       " 11127,\n",
       " 11149,\n",
       " 11337,\n",
       " 11378,\n",
       " 11573,\n",
       " 11588,\n",
       " 11868,\n",
       " 12067,\n",
       " 12321,\n",
       " 12467,\n",
       " 12649,\n",
       " 12722,\n",
       " 12781,\n",
       " 12898,\n",
       " 13023,\n",
       " 13214,\n",
       " 13615,\n",
       " 13651,\n",
       " 14050,\n",
       " 14743,\n",
       " 15195,\n",
       " 15196,\n",
       " 15197,\n",
       " 15622,\n",
       " 15881,\n",
       " 16640,\n",
       " 16735,\n",
       " 16900,\n",
       " 16981,\n",
       " 17125,\n",
       " 17162,\n",
       " 17250,\n",
       " 18116,\n",
       " 18122,\n",
       " 18254,\n",
       " 18266,\n",
       " 18373,\n",
       " 18405,\n",
       " 18512,\n",
       " 18579,\n",
       " 18580,\n",
       " 18750,\n",
       " 19063,\n",
       " 19380,\n",
       " 19543,\n",
       " 21327,\n",
       " 21484,\n",
       " 21671,\n",
       " 21686,\n",
       " 22188,\n",
       " 22463,\n",
       " 22628,\n",
       " 22917,\n",
       " 22995,\n",
       " 23754,\n",
       " 23772,\n",
       " 24128,\n",
       " 24178,\n",
       " 24213,\n",
       " 24520,\n",
       " 24580,\n",
       " 24583,\n",
       " 25190,\n",
       " 25354,\n",
       " 26114,\n",
       " 26582,\n",
       " 27494,\n",
       " 28251,\n",
       " 28351,\n",
       " 28676,\n",
       " 30118,\n",
       " 30119,\n",
       " 30324,\n",
       " 30474,\n",
       " 30735,\n",
       " 30868,\n",
       " 31242,\n",
       " 31491,\n",
       " 32071,\n",
       " 32261,\n",
       " 32894,\n",
       " 33569,\n",
       " 34449,\n",
       " 35870,\n",
       " 37415,\n",
       " 37435,\n",
       " 37732,\n",
       " 37739,\n",
       " 37781,\n",
       " 37793,\n",
       " 38262,\n",
       " 38343,\n",
       " 38447,\n",
       " 38709,\n",
       " 39916,\n",
       " 40425,\n",
       " 40483,\n",
       " 41069,\n",
       " 41681,\n",
       " 41865,\n",
       " 42389,\n",
       " 42696,\n",
       " 42986,\n",
       " 42989,\n",
       " 43448,\n",
       " 43641,\n",
       " 43931,\n",
       " 45432,\n",
       " 46170,\n",
       " 46756,\n",
       " 46787,\n",
       " 46799,\n",
       " 47970,\n",
       " 48855,\n",
       " 49746,\n",
       " 50275,\n",
       " 50798,\n",
       " 50925,\n",
       " 51606,\n",
       " 51789,\n",
       " 51799,\n",
       " 51948,\n",
       " 53835,\n",
       " 54270,\n",
       " 55139,\n",
       " 56373,\n",
       " 58345,\n",
       " 59145,\n",
       " 59963,\n",
       " 60200,\n",
       " 61179,\n",
       " 61773,\n",
       " 65249,\n",
       " 66370,\n",
       " 66929,\n",
       " 67513,\n",
       " 68218,\n",
       " 70101,\n",
       " 70561,\n",
       " 71771,\n",
       " 72003,\n",
       " 72657,\n",
       " 73723,\n",
       " 74760,\n",
       " 75234,\n",
       " 75502,\n",
       " 76401,\n",
       " 76670,\n",
       " 77013,\n",
       " 77142,\n",
       " 77203,\n",
       " 77239,\n",
       " 77767,\n",
       " 77903,\n",
       " 80675,\n",
       " 82333,\n",
       " 82970,\n",
       " 83202,\n",
       " 85386,\n",
       " 85679,\n",
       " 86820,\n",
       " 86845,\n",
       " 87280,\n",
       " 89723,\n",
       " 92057,\n",
       " 92508,\n",
       " 92936,\n",
       " 93981,\n",
       " 94153,\n",
       " 95144,\n",
       " 96358,\n",
       " 97869,\n",
       " 98969,\n",
       " 99319,\n",
       " 99329,\n",
       " 99442,\n",
       " 99955,\n",
       " 100915,\n",
       " 104734,\n",
       " 111000,\n",
       " 111050,\n",
       " 112219,\n",
       " 116114,\n",
       " 116494,\n",
       " 117833,\n",
       " 117835,\n",
       " 117997,\n",
       " 118041,\n",
       " 119322,\n",
       " 119324,\n",
       " 122756,\n",
       " 123653,\n",
       " 123668,\n",
       " 127020,\n",
       " 127953,\n",
       " 128029,\n",
       " 130208,\n",
       " 130440,\n",
       " 133518,\n",
       " 135479,\n",
       " 135836,\n",
       " 136251,\n",
       " 138202,\n",
       " 140082,\n",
       " 140963,\n",
       " 141077,\n",
       " 143555,\n",
       " 146665,\n",
       " 147029,\n",
       " 147728,\n",
       " 147894,\n",
       " 149942,\n",
       " 150373,\n",
       " 152662,\n",
       " 153747,\n",
       " 159273,\n",
       " 160939,\n",
       " 163465,\n",
       " 168642,\n",
       " 168668,\n",
       " 169756,\n",
       " 170453,\n",
       " 170529,\n",
       " 170821,\n",
       " 177523,\n",
       " 187149,\n",
       " 195144,\n",
       " 199687,\n",
       " 200566,\n",
       " 201866,\n",
       " 203220,\n",
       " 203998,\n",
       " 207266,\n",
       " 207577,\n",
       " 214760,\n",
       " 222507,\n",
       " 229001,\n",
       " 231804,\n",
       " 232576,\n",
       " 240129,\n",
       " 248070,\n",
       " 248871,\n",
       " 251547,\n",
       " 253106,\n",
       " 253582,\n",
       " 256683,\n",
       " 259836,\n",
       " 259991,\n",
       " 265008,\n",
       " 268302,\n",
       " 270730,\n",
       " 271199,\n",
       " 275840,\n",
       " 275841,\n",
       " 282773,\n",
       " 289663,\n",
       " 296662,\n",
       " 298275,\n",
       " 301022,\n",
       " 301023,\n",
       " 305234,\n",
       " 308534,\n",
       " 309382,\n",
       " 310459,\n",
       " 316420,\n",
       " 316575,\n",
       " 320197,\n",
       " 321950,\n",
       " 322351,\n",
       " 324663,\n",
       " 331319,\n",
       " 332613,\n",
       " 334286,\n",
       " 337113,\n",
       " 338798,\n",
       " 341055,\n",
       " 342209,\n",
       " 342555,\n",
       " 344189,\n",
       " 346023,\n",
       " 355697,\n",
       " 357636,\n",
       " 370493,\n",
       " 373755,\n",
       " 374188,\n",
       " 374773,\n",
       " 375802,\n",
       " 380285,\n",
       " 386187,\n",
       " 386286,\n",
       " 389424,\n",
       " 393301,\n",
       " 402012,\n",
       " 411855,\n",
       " 411859,\n",
       " 421280,\n",
       " 422146,\n",
       " 430368,\n",
       " 437428,\n",
       " 439288,\n",
       " 446761,\n",
       " 457264,\n",
       " 457762,\n",
       " 472331,\n",
       " 478659,\n",
       " 482976,\n",
       " 485894,\n",
       " 498359,\n",
       " 515678,\n",
       " 517061,\n",
       " 526869,\n",
       " 526927,\n",
       " 530270,\n",
       " 532238,\n",
       " 545951,\n",
       " 560026,\n",
       " 567720,\n",
       " 575241,\n",
       " 575242,\n",
       " 580970,\n",
       " 584937,\n",
       " 592657,\n",
       " 595375,\n",
       " 608787,\n",
       " 625732,\n",
       " 629429,\n",
       " 676737,\n",
       " 693208,\n",
       " 703292,\n",
       " 708481,\n",
       " 709381,\n",
       " 716397,\n",
       " 751591,\n",
       " 753956,\n",
       " 759947,\n",
       " 767307,\n",
       " 773951,\n",
       " 776407,\n",
       " 781820,\n",
       " 784339,\n",
       " 791133,\n",
       " 799475,\n",
       " 816473,\n",
       " 820285,\n",
       " 825473,\n",
       " 849939,\n",
       " 862041,\n",
       " 869906,\n",
       " 871294,\n",
       " 877801,\n",
       " 898435,\n",
       " 899098,\n",
       " 907297,\n",
       " 920143,\n",
       " 931906,\n",
       " 936025,\n",
       " 941720,\n",
       " 953412,\n",
       " 958277,\n",
       " 958289,\n",
       " 971569,\n",
       " 1031803,\n",
       " 1032019,\n",
       " 1097577,\n",
       " 1110887,\n",
       " 1138034,\n",
       " 1144034,\n",
       " 1173584,\n",
       " 1183998,\n",
       " 1192430,\n",
       " 1206058,\n",
       " 1242145,\n",
       " 1281258,\n",
       " 1316617,\n",
       " 1325218,\n",
       " 1328088,\n",
       " 1421804,\n",
       " 1486923,\n",
       " 1518400,\n",
       " 1531254,\n",
       " 1651302,\n",
       " 1786331,\n",
       " 1787387,\n",
       " 1808778,\n",
       " 1843175,\n",
       " 1846075,\n",
       " 1923820,\n",
       " 1949584,\n",
       " 2023676,\n",
       " 2026424,\n",
       " 2303689,\n",
       " 2376087,\n",
       " 2429135,\n",
       " 2454079,\n",
       " 2463554,\n",
       " 2612801,\n",
       " 2767052,\n",
       " 2815590,\n",
       " 2864430,\n",
       " 2977487,\n",
       " 3153910,\n",
       " 3198735,\n",
       " 3236492,\n",
       " 3374236,\n",
       " 3712484,\n",
       " 3753416,\n",
       " 4134071,\n",
       " 4481365,\n",
       " 4555477,\n",
       " 4799029,\n",
       " 4836021,\n",
       " 5168517,\n",
       " 5506846,\n",
       " 5519394,\n",
       " 5883777,\n",
       " 5890586,\n",
       " 5955666,\n",
       " 6050182,\n",
       " 6065110,\n",
       " 6080337,\n",
       " 6148028,\n",
       " 6219656,\n",
       " 6351885,\n",
       " 6379158,\n",
       " 6389263,\n",
       " 6443349,\n",
       " 6482103,\n",
       " 6588662,\n",
       " 6675710,\n",
       " 6713028,\n",
       " 6726938,\n",
       " 6788165,\n",
       " 6792458,\n",
       " 6837103,\n",
       " 6901097,\n",
       " 6916963,\n",
       " 7196914,\n",
       " 7222742,\n",
       " 7260188,\n",
       " 7641383,\n",
       " 7648269,\n",
       " 7747422,\n",
       " 7905977,\n",
       " 7938275,\n",
       " 7971693,\n",
       " 8152939,\n",
       " 8513153,\n",
       " 8695301,\n",
       " 8709523,\n",
       " 9571617,\n",
       " 9583508,\n",
       " 9646992,\n",
       " 9923138,\n",
       " 10097680,\n",
       " 10138607,\n",
       " 10420795,\n",
       " 10431447,\n",
       " 10469840,\n",
       " 11110218,\n",
       " 11253959,\n",
       " 11339141,\n",
       " 11385665,\n",
       " 11595276,\n",
       " 11807189,\n",
       " 11870085,\n",
       " 11886577,\n",
       " 12177850,\n",
       " 12232938,\n",
       " 12369821,\n",
       " 12395877,\n",
       " 12700353,\n",
       " 12804425,\n",
       " 12988846,\n",
       " 12995883,\n",
       " 13079982,\n",
       " 13318633,\n",
       " 13436373,\n",
       " 13528430,\n",
       " 13536858,\n",
       " 13545414,\n",
       " 13563050,\n",
       " 13564820,\n",
       " 13565676,\n",
       " 13593526,\n",
       " 13594616,\n",
       " 13640184,\n",
       " 14926590,\n",
       " 15704307,\n",
       " 15745753,\n",
       " 15798660,\n",
       " 16096824,\n",
       " 16225719,\n",
       " 17376287,\n",
       " 17405942,\n",
       " 17573532,\n",
       " 17857619,\n",
       " 17857704,\n",
       " 17899948,\n",
       " 18114322,\n",
       " 18465634,\n",
       " 18615267,\n",
       " 18733034,\n",
       " 18758839,\n",
       " 18763344,\n",
       " 18803806,\n",
       " 18843442,\n",
       " 19170022,\n",
       " 19322890,\n",
       " 19869794,\n",
       " 20157501,\n",
       " 22435785,\n",
       " 22462625,\n",
       " 22747838,\n",
       " 22754644,\n",
       " 22784968,\n",
       " 22808339,\n",
       " 22821333,\n",
       " 22889878,\n",
       " 23010869,\n",
       " 23574690,\n",
       " 23918613,\n",
       " 24263233,\n",
       " 24484259,\n",
       " 24612624,\n",
       " 25256386,\n",
       " 25573826,\n",
       " 25898216,\n",
       " 26073150,\n",
       " 26135825,\n",
       " 26214355,\n",
       " 27401763,\n",
       " 27401866,\n",
       " 28043983,\n",
       " 28954063,\n",
       " 29202269,\n",
       " 29559052,\n",
       " 29776603,\n",
       " 29844228,\n",
       " 30163876,\n",
       " 30372452,\n",
       " 31450852,\n",
       " 31559033,\n",
       " 32768522,\n",
       " 32825168,\n",
       " 33574273,\n",
       " 33800300,\n",
       " 34331569,\n",
       " 34457278,\n",
       " 34828777,\n",
       " 35031085,\n",
       " 35068524,\n",
       " 35152052,\n",
       " 35276743,\n",
       " 35295478,\n",
       " 35489159,\n",
       " 35717446,\n",
       " 35747029,\n",
       " 35873899,\n",
       " 36219542,\n",
       " 36236124,\n",
       " 36373395,\n",
       " 36949926,\n",
       " 37539457,\n",
       " 37643470,\n",
       " 37953987,\n",
       " 39319247,\n",
       " 40265832,\n",
       " 41189928,\n",
       " 41473872,\n",
       " 41817486,\n",
       " 41887005,\n",
       " 41940333,\n",
       " 42837514,\n",
       " 44017627,\n",
       " 44280883,\n",
       " 45014012,\n",
       " 48730202,\n",
       " 49583709,\n",
       " 50160417,\n",
       " 50548197,\n",
       " 51152447,\n",
       " 51323334,\n",
       " 51599853,\n",
       " 52076947,\n",
       " 52190991,\n",
       " 52220686,\n",
       " 52340895,\n",
       " 52751410,\n",
       " 52892857,\n",
       " 54250984,\n",
       " 54857024,\n",
       " 54998251,\n",
       " 55643287,\n",
       " 57717410,\n",
       " 59336279,\n",
       " 59899216,\n",
       " 60000834,\n",
       " 60694649,\n",
       " 61439040,\n",
       " 123957806]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the bookID column in the dataframe and create a list\n",
    "bookIDs = df['bookID'].unique().astype(int)\n",
    "bookIDs = np.sort(bookIDs).tolist()\n",
    "bookIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the list of ID's to a text file to use for scraping the remaing book data\n",
    "with open('book_IDs.txt', 'w') as f:\n",
    "    for item in bookIDs:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Collect the Book Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before scraping make a new folder to store all the output files. Make sure you are in the correct directory, then type the code below into the command line. If using VS Code, select the code below then go to Terminal, Run Selected Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir banned_book_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start scraping run the `get_book_data.py` script in the command line (or Terminal). Direct it to place output files in the folder `/banned_book__data` and set the file format of the compiled book data to CSV. To scrape a small sample of the books use `book_IDs_sample.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python get_book_data.py --book_ids_path book_IDs.txt --output_directory_path banned_book_data --format csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-08 15:34:47.912842 get_book_data.py: Scraping 42837514...\n",
      "2024-08-08 15:34:47.912842 get_book_data.py: #1 out of 5 books\n",
      "=============================\n",
      "2024-08-08 15:35:12.866216 get_book_data.py: Scraping 44280883...\n",
      "2024-08-08 15:35:12.866216 get_book_data.py: #2 out of 5 books\n",
      "=============================\n",
      "2024-08-08 15:35:39.039447 get_book_data.py: Scraping 22074335...\n",
      "2024-08-08 15:35:39.039447 get_book_data.py: #3 out of 5 books\n",
      "=============================\n",
      "2024-08-08 15:35:47.708095 get_book_data.py: Scraping 214335039...\n",
      "2024-08-08 15:35:47.708095 get_book_data.py: #4 out of 5 books\n",
      "=============================\n",
      "2024-08-08 15:35:52.521699 get_book_data.py: Scraping 292327...\n",
      "2024-08-08 15:35:52.521699 get_book_data.py: #5 out of 5 books\n",
      "=============================\n",
      "2024-08-08 15:36:02.254511 get_book_data.py:\n",
      "\n",
      "🙌 Success! All book data scraped. 🙌\n",
      "\n",
      "Data files output to /banned_book_data\n",
      "Total scraping run time = ⏳ 0:01:14.341669 ⌛\n"
     ]
    }
   ],
   "source": [
    "!python get_book_data.py --book_ids_path book_IDs_sample.txt --output_directory_path banned_book_data --format csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the script has completed the compiled data can be viewed by reading to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id_title</th>\n",
       "      <th>book_id</th>\n",
       "      <th>cover_image_uri</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_series</th>\n",
       "      <th>book_series_uri</th>\n",
       "      <th>top_5_other_editions</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>year_first_published</th>\n",
       "      <th>...</th>\n",
       "      <th>author</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>genres</th>\n",
       "      <th>shelves</th>\n",
       "      <th>lists</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_distribution</th>\n",
       "      <th>reviews_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10138607</td>\n",
       "      <td>10138607</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Habibi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/work/editions/15036678</td>\n",
       "      <td>9780375424</td>\n",
       "      <td>9780375424144</td>\n",
       "      <td>September 1, 2011</td>\n",
       "      <td>...</td>\n",
       "      <td>Craig Thompson</td>\n",
       "      <td>672</td>\n",
       "      <td>['Graphic Novels', 'Comics', 'Fiction', 'Graph...</td>\n",
       "      <td>{'to-read': 48146, 'graphic-novels': 2455, 'gr...</td>\n",
       "      <td>{'Best Graphic Novels': [38, 3359], 'Required ...</td>\n",
       "      <td>42,085</td>\n",
       "      <td>3,976</td>\n",
       "      <td>4.03</td>\n",
       "      <td>{'5 Stars': 1544, '4 Stars': 2490, '3 Stars': ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10138607/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10818853</td>\n",
       "      <td>10818853</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>Fifty Shades</td>\n",
       "      <td>https://www.goodreads.com/series/63134-fifty-s...</td>\n",
       "      <td>https://www.goodreads.com/work/editions/15732562</td>\n",
       "      <td>9781612130</td>\n",
       "      <td>9781612130293</td>\n",
       "      <td>May 25, 2011</td>\n",
       "      <td>...</td>\n",
       "      <td>E.L. James</td>\n",
       "      <td>356</td>\n",
       "      <td>['Romance', 'Fiction', 'Erotica', 'BDSM', 'Adu...</td>\n",
       "      <td>{'to-read': 715974, 'currently-reading': 51995...</td>\n",
       "      <td>{'Best Book Boyfriends': [2, 10180], 'Best M/F...</td>\n",
       "      <td>2,659,011</td>\n",
       "      <td>84,832</td>\n",
       "      <td>3.66</td>\n",
       "      <td>{'5 Stars': 295769, '4 Stars': 276111, '3 Star...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10818853/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10917</td>\n",
       "      <td>10917</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>My Sister’s Keeper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/work/editions/1639903</td>\n",
       "      <td>9780743454</td>\n",
       "      <td>9780743454537</td>\n",
       "      <td>April 6, 2004</td>\n",
       "      <td>...</td>\n",
       "      <td>Jodi Picoult</td>\n",
       "      <td>423</td>\n",
       "      <td>['Fiction', 'Chick Lit', 'Young Adult', 'Drama...</td>\n",
       "      <td>{'to-read': 335130, 'currently-reading': 8931,...</td>\n",
       "      <td>{'Best Books Ever': [83, 122775], 'Best Books ...</td>\n",
       "      <td>1,231,031</td>\n",
       "      <td>38,093</td>\n",
       "      <td>4.10</td>\n",
       "      <td>{'5 Stars': 21917, '4 Stars': 53698, '3 Stars'...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10917/revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11330361</td>\n",
       "      <td>11330361</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>A Stolen Life</td>\n",
       "      <td>Jaycee Dugard</td>\n",
       "      <td>https://www.goodreads.com/series/368303-jaycee...</td>\n",
       "      <td>https://www.goodreads.com/work/editions/16258764</td>\n",
       "      <td>9781451629</td>\n",
       "      <td>9781451629187</td>\n",
       "      <td>July 11, 2011</td>\n",
       "      <td>...</td>\n",
       "      <td>Jaycee Dugard</td>\n",
       "      <td>273</td>\n",
       "      <td>['Nonfiction', 'Memoir', 'True Crime', 'Biogra...</td>\n",
       "      <td>{'to-read': 111068, 'currently-reading': 4090,...</td>\n",
       "      <td>{'Kidnapped!': [21, 773], 'Books That Everyone...</td>\n",
       "      <td>126,111</td>\n",
       "      <td>10,174</td>\n",
       "      <td>3.95</td>\n",
       "      <td>{'5 Stars': 2011, '4 Stars': 6657, '3 Stars': ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/11330361/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11330361</td>\n",
       "      <td>11330361</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>A Stolen Life</td>\n",
       "      <td>Jaycee Dugard</td>\n",
       "      <td>https://www.goodreads.com/series/368303-jaycee...</td>\n",
       "      <td>https://www.goodreads.com/work/editions/16258764</td>\n",
       "      <td>9781451629</td>\n",
       "      <td>9781451629187</td>\n",
       "      <td>July 11, 2011</td>\n",
       "      <td>...</td>\n",
       "      <td>Jaycee Dugard</td>\n",
       "      <td>273</td>\n",
       "      <td>['Nonfiction', 'Memoir', 'True Crime', 'Biogra...</td>\n",
       "      <td>{'to-read': 111062, 'currently-reading': 4094,...</td>\n",
       "      <td>{'Kidnapped!': [21, 773], 'Books That Everyone...</td>\n",
       "      <td>126,102</td>\n",
       "      <td>10,174</td>\n",
       "      <td>3.95</td>\n",
       "      <td>{'5 Stars': 2011, '4 Stars': 6657, '3 Stars': ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/11330361/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>95144</td>\n",
       "      <td>95144</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>In the Night Kitchen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/work/editions/2223682</td>\n",
       "      <td>9780099417</td>\n",
       "      <td>9780099417477</td>\n",
       "      <td>January 1, 1970</td>\n",
       "      <td>...</td>\n",
       "      <td>Maurice Sendak</td>\n",
       "      <td>40</td>\n",
       "      <td>['Picture Books', 'Childrens', 'Fiction', 'Fan...</td>\n",
       "      <td>{'to-read': 6526, 'picture-books': 710, 'child...</td>\n",
       "      <td>{\"Best Children's Books\": [172, 5117], 'Best B...</td>\n",
       "      <td>18,404</td>\n",
       "      <td>997</td>\n",
       "      <td>4.00</td>\n",
       "      <td>{'5 Stars': 672, '4 Stars': 1267, '3 Stars': 3...</td>\n",
       "      <td>https://www.goodreads.com/book/show/95144/revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>9516</td>\n",
       "      <td>9516</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Persepolis: The Story of a Childhood</td>\n",
       "      <td>Persepolis</td>\n",
       "      <td>https://www.goodreads.com/series/45795-persepolis</td>\n",
       "      <td>https://www.goodreads.com/work/editions/3303888</td>\n",
       "      <td>9780375714</td>\n",
       "      <td>9780375714573</td>\n",
       "      <td>April 29, 2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Marjane Satrapi</td>\n",
       "      <td>153</td>\n",
       "      <td>['Graphic Novels', 'Nonfiction', 'Memoir', 'Co...</td>\n",
       "      <td>{'to-read': 141765, 'graphic-novels': 5800, 'g...</td>\n",
       "      <td>{'Best Books of the Decade: 2000s': [68, 7129]...</td>\n",
       "      <td>212,336</td>\n",
       "      <td>12,222</td>\n",
       "      <td>4.26</td>\n",
       "      <td>{'5 Stars': 2252, '4 Stars': 5499, '3 Stars': ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9516/revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>958289</td>\n",
       "      <td>958289</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Skippyjon Jones</td>\n",
       "      <td>Skippyjon Jones</td>\n",
       "      <td>https://www.goodreads.com/series/60536-skippyj...</td>\n",
       "      <td>https://www.goodreads.com/work/editions/649854</td>\n",
       "      <td>9780142404</td>\n",
       "      <td>9780142404034</td>\n",
       "      <td>September 15, 2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Judy Schachner</td>\n",
       "      <td>32</td>\n",
       "      <td>['Picture Books', 'Childrens', 'Animals', 'Fic...</td>\n",
       "      <td>{'to-read': 5912, 'picture-books': 740, 'child...</td>\n",
       "      <td>{'Boy Friendly Picture Books': [35, 190], 'Bes...</td>\n",
       "      <td>34,633</td>\n",
       "      <td>1,431</td>\n",
       "      <td>4.22</td>\n",
       "      <td>{'5 Stars': 1051, '4 Stars': 1685, '3 Stars': ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/958289/rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>968</td>\n",
       "      <td>968</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>The da Vinci Code</td>\n",
       "      <td>Robert Langdon</td>\n",
       "      <td>https://www.goodreads.com/series/92467-robert-...</td>\n",
       "      <td>https://www.goodreads.com/work/editions/2982101</td>\n",
       "      <td>isbn not found</td>\n",
       "      <td>isbn13 not found</td>\n",
       "      <td>January 1, 2003</td>\n",
       "      <td>...</td>\n",
       "      <td>Dan Brown</td>\n",
       "      <td>489</td>\n",
       "      <td>['Fiction', 'Mystery', 'Thriller', 'Mystery Th...</td>\n",
       "      <td>{'to-read': 540941, 'currently-reading': 23689...</td>\n",
       "      <td>{'Best Books Ever': [20, 122774], 'The BOOK wa...</td>\n",
       "      <td>2,380,081</td>\n",
       "      <td>55,573</td>\n",
       "      <td>3.92</td>\n",
       "      <td>{'5 Stars': 87018, '4 Stars': 158677, '3 Stars...</td>\n",
       "      <td>https://www.goodreads.com/book/show/968/review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>99561</td>\n",
       "      <td>99561</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>Looking for Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/work/editions/919292</td>\n",
       "      <td>9781435249</td>\n",
       "      <td>9781435249158</td>\n",
       "      <td>March 3, 2005</td>\n",
       "      <td>...</td>\n",
       "      <td>John Green</td>\n",
       "      <td>221</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Contemporary', 'Ro...</td>\n",
       "      <td>{'to-read': 768711, 'currently-reading': 33105...</td>\n",
       "      <td>{'Best Young Adult Books': [17, 12743], 'Best ...</td>\n",
       "      <td>1,630,342</td>\n",
       "      <td>77,013</td>\n",
       "      <td>3.97</td>\n",
       "      <td>{'5 Stars': 40930, '4 Stars': 107858, '3 Stars...</td>\n",
       "      <td>https://www.goodreads.com/book/show/99561/revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     book_id_title   book_id  \\\n",
       "0         10138607  10138607   \n",
       "1         10818853  10818853   \n",
       "2            10917     10917   \n",
       "3         11330361  11330361   \n",
       "4         11330361  11330361   \n",
       "..             ...       ...   \n",
       "138          95144     95144   \n",
       "139           9516      9516   \n",
       "140         958289    958289   \n",
       "141            968       968   \n",
       "142          99561     99561   \n",
       "\n",
       "                                       cover_image_uri  \\\n",
       "0    https://images-na.ssl-images-amazon.com/images...   \n",
       "1    https://images-na.ssl-images-amazon.com/images...   \n",
       "2    https://images-na.ssl-images-amazon.com/images...   \n",
       "3    https://images-na.ssl-images-amazon.com/images...   \n",
       "4    https://images-na.ssl-images-amazon.com/images...   \n",
       "..                                                 ...   \n",
       "138  https://images-na.ssl-images-amazon.com/images...   \n",
       "139  https://images-na.ssl-images-amazon.com/images...   \n",
       "140  https://images-na.ssl-images-amazon.com/images...   \n",
       "141  https://images-na.ssl-images-amazon.com/images...   \n",
       "142  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                               book_title      book_series  \\\n",
       "0                                  Habibi              NaN   \n",
       "1                    Fifty Shades of Grey     Fifty Shades   \n",
       "2                      My Sister’s Keeper              NaN   \n",
       "3                           A Stolen Life    Jaycee Dugard   \n",
       "4                           A Stolen Life    Jaycee Dugard   \n",
       "..                                    ...              ...   \n",
       "138                  In the Night Kitchen              NaN   \n",
       "139  Persepolis: The Story of a Childhood       Persepolis   \n",
       "140                       Skippyjon Jones  Skippyjon Jones   \n",
       "141                     The da Vinci Code   Robert Langdon   \n",
       "142                    Looking for Alaska              NaN   \n",
       "\n",
       "                                       book_series_uri  \\\n",
       "0                                                  NaN   \n",
       "1    https://www.goodreads.com/series/63134-fifty-s...   \n",
       "2                                                  NaN   \n",
       "3    https://www.goodreads.com/series/368303-jaycee...   \n",
       "4    https://www.goodreads.com/series/368303-jaycee...   \n",
       "..                                                 ...   \n",
       "138                                                NaN   \n",
       "139  https://www.goodreads.com/series/45795-persepolis   \n",
       "140  https://www.goodreads.com/series/60536-skippyj...   \n",
       "141  https://www.goodreads.com/series/92467-robert-...   \n",
       "142                                                NaN   \n",
       "\n",
       "                                 top_5_other_editions            isbn  \\\n",
       "0    https://www.goodreads.com/work/editions/15036678      9780375424   \n",
       "1    https://www.goodreads.com/work/editions/15732562      9781612130   \n",
       "2     https://www.goodreads.com/work/editions/1639903      9780743454   \n",
       "3    https://www.goodreads.com/work/editions/16258764      9781451629   \n",
       "4    https://www.goodreads.com/work/editions/16258764      9781451629   \n",
       "..                                                ...             ...   \n",
       "138   https://www.goodreads.com/work/editions/2223682      9780099417   \n",
       "139   https://www.goodreads.com/work/editions/3303888      9780375714   \n",
       "140    https://www.goodreads.com/work/editions/649854      9780142404   \n",
       "141   https://www.goodreads.com/work/editions/2982101  isbn not found   \n",
       "142    https://www.goodreads.com/work/editions/919292      9781435249   \n",
       "\n",
       "               isbn13 year_first_published  ...           author num_pages  \\\n",
       "0       9780375424144    September 1, 2011  ...   Craig Thompson       672   \n",
       "1       9781612130293         May 25, 2011  ...       E.L. James       356   \n",
       "2       9780743454537        April 6, 2004  ...     Jodi Picoult       423   \n",
       "3       9781451629187        July 11, 2011  ...    Jaycee Dugard       273   \n",
       "4       9781451629187        July 11, 2011  ...    Jaycee Dugard       273   \n",
       "..                ...                  ...  ...              ...       ...   \n",
       "138     9780099417477      January 1, 1970  ...   Maurice Sendak        40   \n",
       "139     9780375714573       April 29, 2003  ...  Marjane Satrapi       153   \n",
       "140     9780142404034   September 15, 2003  ...   Judy Schachner        32   \n",
       "141  isbn13 not found      January 1, 2003  ...        Dan Brown       489   \n",
       "142     9781435249158        March 3, 2005  ...       John Green       221   \n",
       "\n",
       "                                                genres  \\\n",
       "0    ['Graphic Novels', 'Comics', 'Fiction', 'Graph...   \n",
       "1    ['Romance', 'Fiction', 'Erotica', 'BDSM', 'Adu...   \n",
       "2    ['Fiction', 'Chick Lit', 'Young Adult', 'Drama...   \n",
       "3    ['Nonfiction', 'Memoir', 'True Crime', 'Biogra...   \n",
       "4    ['Nonfiction', 'Memoir', 'True Crime', 'Biogra...   \n",
       "..                                                 ...   \n",
       "138  ['Picture Books', 'Childrens', 'Fiction', 'Fan...   \n",
       "139  ['Graphic Novels', 'Nonfiction', 'Memoir', 'Co...   \n",
       "140  ['Picture Books', 'Childrens', 'Animals', 'Fic...   \n",
       "141  ['Fiction', 'Mystery', 'Thriller', 'Mystery Th...   \n",
       "142  ['Young Adult', 'Fiction', 'Contemporary', 'Ro...   \n",
       "\n",
       "                                               shelves  \\\n",
       "0    {'to-read': 48146, 'graphic-novels': 2455, 'gr...   \n",
       "1    {'to-read': 715974, 'currently-reading': 51995...   \n",
       "2    {'to-read': 335130, 'currently-reading': 8931,...   \n",
       "3    {'to-read': 111068, 'currently-reading': 4090,...   \n",
       "4    {'to-read': 111062, 'currently-reading': 4094,...   \n",
       "..                                                 ...   \n",
       "138  {'to-read': 6526, 'picture-books': 710, 'child...   \n",
       "139  {'to-read': 141765, 'graphic-novels': 5800, 'g...   \n",
       "140  {'to-read': 5912, 'picture-books': 740, 'child...   \n",
       "141  {'to-read': 540941, 'currently-reading': 23689...   \n",
       "142  {'to-read': 768711, 'currently-reading': 33105...   \n",
       "\n",
       "                                                 lists num_ratings  \\\n",
       "0    {'Best Graphic Novels': [38, 3359], 'Required ...      42,085   \n",
       "1    {'Best Book Boyfriends': [2, 10180], 'Best M/F...   2,659,011   \n",
       "2    {'Best Books Ever': [83, 122775], 'Best Books ...   1,231,031   \n",
       "3    {'Kidnapped!': [21, 773], 'Books That Everyone...     126,111   \n",
       "4    {'Kidnapped!': [21, 773], 'Books That Everyone...     126,102   \n",
       "..                                                 ...         ...   \n",
       "138  {\"Best Children's Books\": [172, 5117], 'Best B...      18,404   \n",
       "139  {'Best Books of the Decade: 2000s': [68, 7129]...     212,336   \n",
       "140  {'Boy Friendly Picture Books': [35, 190], 'Bes...      34,633   \n",
       "141  {'Best Books Ever': [20, 122774], 'The BOOK wa...   2,380,081   \n",
       "142  {'Best Young Adult Books': [17, 12743], 'Best ...   1,630,342   \n",
       "\n",
       "    num_reviews average_rating  \\\n",
       "0         3,976           4.03   \n",
       "1        84,832           3.66   \n",
       "2        38,093           4.10   \n",
       "3        10,174           3.95   \n",
       "4        10,174           3.95   \n",
       "..          ...            ...   \n",
       "138         997           4.00   \n",
       "139      12,222           4.26   \n",
       "140       1,431           4.22   \n",
       "141      55,573           3.92   \n",
       "142      77,013           3.97   \n",
       "\n",
       "                                   rating_distribution  \\\n",
       "0    {'5 Stars': 1544, '4 Stars': 2490, '3 Stars': ...   \n",
       "1    {'5 Stars': 295769, '4 Stars': 276111, '3 Star...   \n",
       "2    {'5 Stars': 21917, '4 Stars': 53698, '3 Stars'...   \n",
       "3    {'5 Stars': 2011, '4 Stars': 6657, '3 Stars': ...   \n",
       "4    {'5 Stars': 2011, '4 Stars': 6657, '3 Stars': ...   \n",
       "..                                                 ...   \n",
       "138  {'5 Stars': 672, '4 Stars': 1267, '3 Stars': 3...   \n",
       "139  {'5 Stars': 2252, '4 Stars': 5499, '3 Stars': ...   \n",
       "140  {'5 Stars': 1051, '4 Stars': 1685, '3 Stars': ...   \n",
       "141  {'5 Stars': 87018, '4 Stars': 158677, '3 Stars...   \n",
       "142  {'5 Stars': 40930, '4 Stars': 107858, '3 Stars...   \n",
       "\n",
       "                                          reviews_page  \n",
       "0    https://www.goodreads.com/book/show/10138607/r...  \n",
       "1    https://www.goodreads.com/book/show/10818853/r...  \n",
       "2    https://www.goodreads.com/book/show/10917/revi...  \n",
       "3    https://www.goodreads.com/book/show/11330361/r...  \n",
       "4    https://www.goodreads.com/book/show/11330361/r...  \n",
       "..                                                 ...  \n",
       "138  https://www.goodreads.com/book/show/95144/revi...  \n",
       "139  https://www.goodreads.com/book/show/9516/revie...  \n",
       "140  https://www.goodreads.com/book/show/958289/rev...  \n",
       "141  https://www.goodreads.com/book/show/968/review...  \n",
       "142  https://www.goodreads.com/book/show/99561/revi...  \n",
       "\n",
       "[143 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_data = pd.read_csv(\"banned_book_data/all_books.csv\")\n",
    "bk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export copy of DataFrame to database\n",
    "bk_data.to_sql(name='all_books', con=conn, if_exists='append', index=False)\n",
    "# If not using sqlite you can also export a copy to csv\n",
    "# bk_data.to_csv('all_books.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Collect Review Data (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the review data for a list of books can be a lengthy process. The average processing time is 1 to 3 minutes for each book. If you still want to compile some book reviews, proceed. Otherwise I have included samples of some book review output as `BookTitle.csv` and the final joined scrape of all reviews from the 'Best Banned, Censored, and Challenged Books' list as `book_reviews.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect all reviews for each book in the List\n",
    "def get_Book_Reviews(page_source):\n",
    "\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "    # Locate book title\n",
    "    title = soup.find('h1', attrs = {'class' : 'Text H1Title'}).text\n",
    "\n",
    "    # Locate all user account hrefs\n",
    "    cont = soup.select('div.ReviewerProfile__name')\n",
    "    hrefsUsers = [x.find('a')['href'] for x in cont]\n",
    "\n",
    "    # Collect user review text\n",
    "    contReview = soup.select(\"section.ReviewText\")\n",
    "    Reviews = [x.text.strip() for x in contReview]\n",
    "\n",
    "    # Collect individual user ratings \n",
    "    contRatingCont = soup.select(\"div.ShelfStatus\")\n",
    "    userRatings = [x.find('span')['aria-label'] if (x.findChildren('span', recursive=False) == []) == False else 'No Rating' for x in contRatingCont]\n",
    "\n",
    "    # Collect the date the review was written\n",
    "    dateCont = soup.select('section.ReviewCard__row')\n",
    "    datesOfReviews = [x.find('span', attrs = {'class': 'Text Text__body3'}).text for x in dateCont]\n",
    "\n",
    "    # Collect number of likes and comments for review\n",
    "    commentLikeCont = soup.select('footer.SocialFooter')\n",
    "    likes = ['0' if x.find('div', attrs={'class': 'SocialFooter__statsContainer'}) == None else x.find('span', attrs={'class': 'Button__labelItem'}).text  for x in commentLikeCont]\n",
    "    comments = ['0' if x.find('div', attrs={'class': 'Button__container'}).next_sibling == None else x.find('div', attrs={'class': 'Button__container'}).next_sibling.text for x in commentLikeCont]\n",
    "\n",
    "    # Create DataFrame of all review data collected\n",
    "\n",
    "    reviewData = pd.DataFrame({ 'User Href' : hrefsUsers,\n",
    "                                'Title' : title,\n",
    "                                'Rating' : userRatings,\n",
    "                                'Date' : datesOfReviews,\n",
    "                                'Likes' : likes,\n",
    "                                'Comments' : comments,\n",
    "                                'Review' : Reviews})\n",
    "    \n",
    "    return(reviewData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if element exists on page\n",
    "def check_element(e):\n",
    "    if e:\n",
    "        return (e)\n",
    "    else:\n",
    "        return (0)\n",
    "\n",
    "# Function to automate loading all reviews    \n",
    "def get_more_reviews(url):\n",
    "    clicks = 0\n",
    "\n",
    "    # Initilaizing driver and webpage and allowing time for reviews to load\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    # headless option allows webbrowser to run in the background\n",
    "    # Remove options if you want to allow visible interface while script is running \n",
    "    driver = webdriver.Edge(options=options)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    try:\n",
    "        nreviews = check_element(int(re.sub('\\\\D', '', soup.find('span', attrs = {'class' : 'Text Text__body3 Text__subdued'}).text)))\n",
    "    except ValueError:\n",
    "        nreviews = int(0)\n",
    "    cap = 36\n",
    "    iters = np.round(nreviews/30)-1\n",
    "\n",
    "\n",
    "    if iters < cap:\n",
    "        while clicks < iters:\n",
    "\n",
    "            # scrolling down page to ensure click will work on \"show more results\" button\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Clicking \"show more results\" button\n",
    "            MoreResults = driver.find_element(By.XPATH, \"//div[@class = 'Divider Divider--contents Divider--largeMargin']/div[@class = 'Button__container']/button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", MoreResults)\n",
    "            time.sleep(1)\n",
    "\n",
    "            clicks += 1\n",
    "    else:\n",
    "        while clicks < cap:\n",
    "\n",
    "            # scrolling down page to ensure click will work on \"show more results\" button\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Clicking \"show more results\" button\n",
    "            MoreResults = driver.find_element(By.XPATH, \"//div[@class = 'Divider Divider--contents Divider--largeMargin']/div[@class = 'Button__container']/button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", MoreResults)\n",
    "            time.sleep(1)\n",
    "\n",
    "            clicks += 1\n",
    "    \n",
    "\n",
    "    # grabbing reference for final state of page after n number of \"show more results\" button clicks\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    reviews = get_Book_Reviews(page_source)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open table containing book links\n",
    "BannedBooksReviews = pd.read_sql_query(\"SELECT * FROM all_books\", conn)\n",
    "# df = pd.read_csv('all_books.csv')\n",
    "# BannedBooksReviews = df['reviews_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing in smaller batches to double check loading into csv was successful\n",
    "for i in range(0, 5):\n",
    "    bookdata = get_more_reviews(BannedBooksReviews['reviews_page'][i])\n",
    "    # Save reviews to csv\n",
    "    # bookdata.to_csv('Book{num}.csv'.format(num=i+1), index=False)\n",
    "    bookdata.to_csv(f'{BannedBooksReviews['book_title'][i]}.csv'.format(num=i+1), index=False)\n",
    "    # Save reviews to database\n",
    "    bookdata.to_sql(name='Book{num}'.format(num=i+1), con=conn, if_exists='append', index=False)\n",
    "    # bookdata.to_sql(name=f'{BannedBooksReviews['book_title'][i]}'.format(num=i+1), con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the script has completed the review data can viewed in the database or in the project folder depending on which save option you chose."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
